[
  {
    "objectID": "mapProject.html",
    "href": "mapProject.html",
    "title": "Maps",
    "section": "",
    "text": "# Initial packages required (we'll be adding more)\nlibrary(tidyverse)\nlibrary(datasets)\nlibrary(fec16)\nlibrary(ggplot2)\nlibrary(tidycensus)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggspatial)\nlibrary(mdsr)      # package associated with our MDSR book\n\n\nlibrary(maps)\nus_states &lt;- map_data(\"state\")\nhead(us_states)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\nStatePopulation &lt;- read.csv(\"https://raw.githubusercontent.com/ds4stats/r-tutorials/master/intro-maps/data/StatePopulation.csv\", as.is = TRUE)\n\n\nus_rent_income |&gt;\n  filter(variable == \"income\") |&gt;\n  mutate(name = str_to_lower(NAME)) |&gt;\n  select(-NAME) |&gt;\n  right_join(us_states, by = c(\"name\" = \"region\")) |&gt;\n  ggplot(mapping = aes(x = long, y = lat,\n                          group = group)) + \n  geom_polygon(aes(fill = estimate), color = \"black\") +\n  labs(title = \"Average 2017 Income by State\", fill = \"Yearly Income (in USD)\") +\n  coord_map() +\n  theme_mdsr()\n\n\n\n\nWe can see that states like Maryland and Washington had a greater yearly income for 2017 while states like Alabama and West Virginia were not as fortuitous. It’s interesting how states like Maryland and Virginia are doing well while their neighbors are all on the other end of the spectrum. One other thing to note is that the Southeast US tended to earn less than most other regions.\n\n# summary of the 8 congressional Wisconsin districts and the 2016 voting\ndistrict_elections &lt;- results_house |&gt;\n  mutate(district = parse_number(district_id)) |&gt;\n  group_by(state, district) |&gt;\n  summarize(\n    N = n(), \n    total_votes = sum(general_votes, na.rm = TRUE),\n    d_votes = sum(ifelse(party == \"DEM\", general_votes, 0), na.rm = TRUE),\n    #we add together all the votes for democrats in the district\n    r_votes = sum(ifelse(party == \"REP\", general_votes, 0), na.rm = TRUE),\n    #same but with only republicans\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    other_votes = total_votes - d_votes - r_votes,\n    r_prop = r_votes / total_votes,  \n    winner = ifelse(r_votes &gt; d_votes, \"Republican\", \"Democrat\")\n  )\n\nwi_results &lt;- district_elections |&gt;\n  filter(state == \"WI\")\nwi_results |&gt;                  \n  select(-state)\n\n\n# Download congressional district shapefiles \noptions(timeout = 200)\nsrc &lt;- \"http://cdmaps.polisci.ucla.edu/shp/districts113.zip\"\nlcl_zip &lt;- fs::path(tempdir(), \"districts113.zip\")\ndownload.file(src, destfile = lcl_zip)\nlcl_districts &lt;- fs::path(tempdir(), \"districts113\")\nunzip(lcl_zip, exdir = lcl_districts)\ndsn_districts &lt;- fs::path(lcl_districts, \"districtShapes\")\n\n\n# read shapefiles into R as an sf object\nst_layers(dsn_districts)\n\n# be able to read as a data frame as well\ndistricts &lt;- st_read(dsn_districts, layer = \"districts113\") |&gt;\n  mutate(DISTRICT = parse_number(as.character(DISTRICT)))\nhead(districts, width = Inf)\nclass(districts)\n\n#####################################\n# create basic plot with Wisconsin congressional districts\nwi_shp &lt;- districts |&gt;\n  filter(STATENAME == \"Wisconsin\")\nwi_shp |&gt;\n  st_geometry() |&gt;\n  plot(col = gray.colors(nrow(wi_shp)))\n\nwi_merged &lt;- wi_shp |&gt;\n  st_transform(4326) |&gt;\n  inner_join(wi_results, by = c(\"DISTRICT\" = \"district\"))\nhead(wi_merged, width = Inf)\n\n\n# Color based on winning party\n#   Note that geom_sf is part of ggplot2 package, while st_geometry is\n#   part of sf package\nwi &lt;- ggplot(data = wi_merged, aes(fill = winner)) +\n  annotation_map_tile(zoom = 6, type = \"osm\", progress = \"none\") + \n  geom_sf(alpha = 0.5) +\n  scale_fill_manual(\"Winning Party\", values = c(\"blue\", \"red\")) + \n  geom_sf_label(aes(label = DISTRICT), fill = \"white\") + \n  theme_void() +\n  labs(title = \"Winners of Wisconsin's Eight Congressional Districts cir. 2016\")\nwi\n\n# Color based on proportion Rep.  Be sure to let limits so centered at 0.5.\n# This is a choropleth map, where meaningful shading relates to some attribute\nwi +\n  aes(fill = r_prop) + \n  scale_fill_distiller(\n    \"Proportion\\nRepublican\", \n    palette = \"RdBu\", \n    limits = c(0, 1)\n  )\n\nFrom this map, we can see that quite a few districts (like 2, 3, and 4) definitely contain a strong democratic population, while the districts that are more in the middle (like 1, 7 and 8) are just ever so slightly right leaning. For a party wanting to gerrymander, you would need to group all your opponent’s voters in a select few borders so that their votes go towards an overwhelming victory in those areas, while yours are spread around so that you use your total voters strategically, just barely pulling off a win. With this map, I can definitely understand the argument that Republicans have lopsided control of the state, since it seems like what few Democratic victories there are have very little Republican pushback."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cole Monson",
    "section": "",
    "text": "he/him/his\nMathematics + Computer Science Major with Statistics and Data Science Concentration at St. Olaf College \nSt. Olaf College\n\n\nA/V Engineer, Chapel Specialist | Broadcast Media\nTA/Grader | MSCS Department\nSt. Olaf Band (Tenor Sax), St. Olaf Handbells"
  },
  {
    "objectID": "index.html#cole-monson",
    "href": "index.html#cole-monson",
    "title": "Cole Monson",
    "section": "",
    "text": "he/him/his\nMathematics + Computer Science Major with Statistics and Data Science Concentration at St. Olaf College \nSt. Olaf College\n\n\nA/V Engineer, Chapel Specialist | Broadcast Media\nTA/Grader | MSCS Department\nSt. Olaf Band (Tenor Sax), St. Olaf Handbells"
  },
  {
    "objectID": "simulationProject.html",
    "href": "simulationProject.html",
    "title": "Simulation",
    "section": "",
    "text": "# Initial packages required\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(mdsr)"
  },
  {
    "objectID": "simulationProject.html#background",
    "href": "simulationProject.html#background",
    "title": "Simulation",
    "section": "Background",
    "text": "Background\nImagine we have new experimental technology to rid Minnesota of springtime snowstorms. Our team of researchers conducts an experiment using this new device over randomly selected areas of Northfield, and compares it with the other half that did not receive any treatment.\nLet’s say that this device really works and the weather has a significant decrease in snowfall for the affected areas. Despite this however, it might not always be clear to our researchers that our test had a significant effect. By chance, we could randomly collect a set of measurements from each group that doesn’t demonstrate a difference seen outside the realm of likelihood.\nIf we carried this test out a good number of times, we would hope to find a statistically low p-value a large proportion of the time. In other words, we would want our test’s power to be large enough so that we can reasonably expect our sample to provide data that correctly rejects the null hypothesis."
  }
]